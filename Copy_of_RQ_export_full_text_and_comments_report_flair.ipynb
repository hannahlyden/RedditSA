{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bcppd0l4oub"
      },
      "outputs": [],
      "source": [
        "# Lets us talk to other servers on the web\n",
        "import requests\n",
        "\n",
        "# APIs spit out data in JSON\n",
        "import json\n",
        "\n",
        "# Use BeautifulSoup to parse some HTML\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Handling dates and times\n",
        "from datetime import datetime\n",
        "\n",
        "# DataFrames!\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data visualization\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install praw\n",
        "!pip install asyncpraw\n",
        "!pip install asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "id": "Hq15l2I_4yML",
        "outputId": "ccfb51bf-6386-4eab-a548-d20facafb7be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praw\n",
            "  Downloading praw-7.7.1-py3-none-any.whl (191 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.0/191.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prawcore<3,>=2.1 (from praw)\n",
            "  Downloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
            "Collecting update-checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.6.3)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.1->praw) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2023.7.22)\n",
            "Installing collected packages: update-checker, prawcore, praw\n",
            "Successfully installed praw-7.7.1 prawcore-2.4.0 update-checker-0.18.0\n",
            "Collecting asyncpraw\n",
            "  Downloading asyncpraw-7.7.1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.7/196.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<1 (from asyncpraw)\n",
            "  Downloading aiofiles-0.8.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: aiohttp<4 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (3.8.5)\n",
            "Collecting aiosqlite<=0.17.0 (from asyncpraw)\n",
            "  Downloading aiosqlite-0.17.0-py3-none-any.whl (15 kB)\n",
            "Collecting asyncprawcore<3,>=2.1 (from asyncpraw)\n",
            "  Downloading asyncprawcore-2.3.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: update-checker>=0.18 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (0.18.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from aiosqlite<=0.17.0->asyncpraw) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from update-checker>=0.18->asyncpraw) (2.31.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.18->asyncpraw) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.18->asyncpraw) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.18->asyncpraw) (2023.7.22)\n",
            "Installing collected packages: aiosqlite, aiofiles, asyncprawcore, asyncpraw\n",
            "Successfully installed aiofiles-0.8.0 aiosqlite-0.17.0 asyncpraw-7.7.1 asyncprawcore-2.3.0\n",
            "Collecting asyncio\n",
            "  Downloading asyncio-3.4.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: asyncio\n",
            "Successfully installed asyncio-3.4.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "asyncio"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "import asyncpraw\n",
        "import asyncio"
      ],
      "metadata": {
        "id": "1jLgiaLi4tk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B6lHEbkABHZ",
        "outputId": "cbc01439-b3f8-4495-fbf3-649c736824bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/My\\ Drive/\n"
      ],
      "metadata": {
        "id": "unKtAiPHFEyh",
        "outputId": "da651052-4fa7-46d6-e319-a2a2f5483c2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "fQyZJA4AFI6D",
        "outputId": "09ecf885-185e-4f38-e575-eb465b1721e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'2019 Sociology Open House.docx'\n",
            "'Boulder Apartments.gdoc'\n",
            "'California Road Trip.gsheet'\n",
            "\u001b[0m\u001b[01;34m'Colab Notebooks'\u001b[0m/\n",
            "'Colorado Road Trip.gsheet'\n",
            "'Copy of Interview Questions.gform'\n",
            "'Copy of Moral Panics Group Sheet.gform'\n",
            "'Copy of SOCY 1001: Week 3.gdoc'\n",
            "'Database Access.gsheet'\n",
            "'DC Nov 4 - Nov 10.gdoc'\n",
            " Epcot.gsheet\n",
            "'Fall 2023 SOCY 2061 Accomodations.gsheet'\n",
            "'Florida South Carolina North Carolina Trip.gdoc'\n",
            "'Frequent Flyer Numbers.gsheet'\n",
            "'History for Josie Lyden.zip'\n",
            "'Impact of the ConRed program on different.png'\n",
            "'Interview Coding.gform'\n",
            "'Interview Questions.gform'\n",
            "'Interview Questions (Responses).gsheet'\n",
            "'Interview Questions Section 101.gform'\n",
            "'Interview Questions Section 102.gform'\n",
            "'Interview Questions Section 111.gform'\n",
            "'Interview Questions Section 111 (Responses).gsheet'\n",
            "\u001b[01;36m'Intro spring 2023'\u001b[0m@\n",
            "'North Carolina.gdoc'\n",
            "'North Carolina.gsheet'\n",
            " of0306.gdoc\n",
            " of0306.pdf\n",
            "\u001b[01;34m'PhD Programs'\u001b[0m/\n",
            " PW.gsheet\n",
            " \u001b[01;36mR\u001b[0m@\n",
            "'Recitation 104 Attendance.gsheet'\n",
            "'Recitation Week 4 Outline.gdoc'\n",
            " \u001b[01;36mReddit_SA_Support\u001b[0m@\n",
            "'SOCY 1001-101 Week 1.gform'\n",
            "'SOCY 1001-102 Week 1.gform'\n",
            "'SOCY 1001-111 Week 1.gform'\n",
            "'SOCY 1001: Week 3 - 101.gdoc'\n",
            "'SOCY 1001 - Week 5.gform'\n",
            "'SOCY 1001 - Week 5 Group Activity .gform'\n",
            "'SOCY 1001: Week 6 Activity.gdoc'\n",
            "'SOCY Week 10 - Race.gform'\n",
            "'TA Lecture Attendance Rotation.gdoc'\n",
            "'Travel planner (1).gsheet'\n",
            "'Travel planner (2).gsheet'\n",
            "'Travel planner.gsheet'\n",
            "'Untitled document.gdoc'\n",
            "'Untitled form.gform'\n",
            "'Untitled spreadsheet (1).gsheet'\n",
            "'Untitled spreadsheet.gsheet'\n",
            "'Week 4 - Research Methods.gform'\n",
            "'Week 4 - Research Methods (Responses).gsheet'\n",
            " Worksheet.gform\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd Reddit_SA_Support\n",
        "\n"
      ],
      "metadata": {
        "id": "DQLmsGvkGPNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_drive_path = '/content/drive/My Drive/'\n",
        "excel_file_path = google_drive_path + '10_11_reddit_data_V4.xlsx'\n"
      ],
      "metadata": {
        "id": "NnVnXvkFALh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import nest_asyncio\n",
        "import asyncpraw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Allow nested event loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "async def get_reddit_post_info():\n",
        "    # Initialize the Reddit instance\n",
        "    reddit = asyncpraw.Reddit(\n",
        "        username=\"groovydragonfruit\",\n",
        "        password=\"QRrKWuCsc8m$H(R\",\n",
        "        client_id=\"dgrSn-ROpsgbKf1-19zV5A\",\n",
        "        client_secret=\"ds9VdI9GZWvk_2kWUJF4uKorP9s6Vw\",\n",
        "        user_agent=\"SAscrape2 by /u/groovydragonfruit\"\n",
        "    )\n",
        "\n",
        "    subreddit_name = \"sexualassault\"  # Replace with the name of the subreddit you want to search in\n",
        "    keywords = ['police', 'cop', 'cops', 'law enforcement', 'report', 'reporting', 'reported']  # Replace with your desired keywords\n",
        "    desired_flair = 'Reporting/Police'  # Replace with the flair you want to filter by\n",
        "\n",
        "    subreddit = await reddit.subreddit(subreddit_name)  # Define subreddit here\n",
        "\n",
        "    data = []  # List to store scraped data\n",
        "\n",
        "    async for submission in subreddit.search(' '.join(keywords), limit=200):\n",
        "        # Check if the submission has the desired keywords or the desired flair\n",
        "        if any(keyword in submission.title.lower() for keyword in keywords) or submission.link_flair_text == desired_flair:\n",
        "            # Convert created_utc to a human-readable date (without time)\n",
        "            created_datetime = datetime.utcfromtimestamp(submission.created_utc)\n",
        "            created_date_str = created_datetime.strftime('%Y-%m-%d')\n",
        "\n",
        "            # Extract relevant information from the submission\n",
        "            submission_data = {\n",
        "                'Title': submission.title,\n",
        "                'URL': submission.url,\n",
        "                'Full Text': submission.selftext,\n",
        "                'Flair': submission.link_flair_text,\n",
        "                'Created Date': created_date_str\n",
        "            }\n",
        "            data.append(submission_data)\n",
        "\n",
        "            # Load the submission to access its comments\n",
        "            submission = await reddit.submission(id=submission.id)\n",
        "            submission.comments.replace_more(limit=None)\n",
        "            for comment in submission.comments.list():\n",
        "                # Convert created_utc to a human-readable date (without time)\n",
        "                comment_created_datetime = datetime.utcfromtimestamp(comment.created_utc)\n",
        "                comment_created_date_str = comment_created_datetime.strftime('%Y-%m-%d')\n",
        "\n",
        "                # Extract relevant information from the comment\n",
        "                comment_data = {\n",
        "                    'Title': submission.title,  # Use the submission title for comments\n",
        "                    'Comment': comment.body,\n",
        "                    'Created Date': comment_created_date_str\n",
        "                }\n",
        "                data.append(comment_data)\n",
        "\n",
        "    # Create a DataFrame from the collected data\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Close the Reddit API client session\n",
        "    await reddit.close()\n",
        "\n",
        "    # Return the DataFrame\n",
        "    return df\n",
        "\n",
        "# Run the asynchronous function using asyncio.run() and store the result in 'df'\n",
        "df = asyncio.run(get_reddit_post_info())\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW2YjJem45wB",
        "outputId": "55b97294-0dbf-43db-f947-f542e81dc73d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-2bff7a9c086b>:47: RuntimeWarning: coroutine 'CommentForest.replace_more' was never awaited\n",
            "  submission.comments.replace_more(limit=None)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                   Title  \\\n",
            "0      Did you report your SA to police?   \n",
            "1      Did you report your SA to police?   \n",
            "2      Did you report your SA to police?   \n",
            "3      Did you report your SA to police?   \n",
            "4      Did you report your SA to police?   \n",
            "..                                   ...   \n",
            "944  Reported to CID despite no evidence   \n",
            "945             I reported their account   \n",
            "946             I reported their account   \n",
            "947             I reported their account   \n",
            "948           I finally reported someone   \n",
            "\n",
            "                                                   URL  \\\n",
            "0    https://www.reddit.com/r/sexualassault/comment...   \n",
            "1                                                  NaN   \n",
            "2                                                  NaN   \n",
            "3                                                  NaN   \n",
            "4                                                  NaN   \n",
            "..                                                 ...   \n",
            "944                                                NaN   \n",
            "945  https://www.reddit.com/r/sexualassault/comment...   \n",
            "946                                                NaN   \n",
            "947                                                NaN   \n",
            "948  https://www.reddit.com/r/sexualassault/comment...   \n",
            "\n",
            "                                             Full Text  \\\n",
            "0    This post isn't to shame anyone who didn't or ...   \n",
            "1                                                  NaN   \n",
            "2                                                  NaN   \n",
            "3                                                  NaN   \n",
            "4                                                  NaN   \n",
            "..                                                 ...   \n",
            "944                                                NaN   \n",
            "945  I met my ex on Tinder in 2018. We were togethe...   \n",
            "946                                                NaN   \n",
            "947                                                NaN   \n",
            "948  I was a waitress at a bar in my town. I had be...   \n",
            "\n",
            "                       Flair Created Date  \\\n",
            "0                   Question   2022-11-09   \n",
            "1                        NaN   2022-11-09   \n",
            "2                        NaN   2022-11-09   \n",
            "3                        NaN   2022-11-09   \n",
            "4                        NaN   2022-11-09   \n",
            "..                       ...          ...   \n",
            "944                      NaN   2021-08-26   \n",
            "945  Progress Has Been Made!   2021-03-29   \n",
            "946                      NaN   2021-03-30   \n",
            "947                      NaN   2021-03-30   \n",
            "948                 My Story   2021-06-03   \n",
            "\n",
            "                                               Comment  \n",
            "0                                                  NaN  \n",
            "1    mine was never reported. I was a kid but my mo...  \n",
            "2    Yeah, but the police never called me, was hopi...  \n",
            "3                                            [removed]  \n",
            "4    No. He had a rich dad and could likely afford ...  \n",
            "..                                                 ...  \n",
            "944        * should have said *additional*, not other.  \n",
            "945                                                NaN  \n",
            "946  I'm so sorry you experienced this. I'm also so...  \n",
            "947  Thank you for this very kind message, it means...  \n",
            "948                                                NaN  \n",
            "\n",
            "[949 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sFt7VA6CpLK",
        "outputId": "a9fa1e43-5e77-45ba-aab0-31a74525aaad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           Title  \\\n",
            "0                        Cops charged me instead   \n",
            "1                        Cops charged me instead   \n",
            "2                        Cops charged me instead   \n",
            "3                        Cops charged me instead   \n",
            "4                        Cops charged me instead   \n",
            "..                                           ...   \n",
            "308  The day I've dreaded for years finally came   \n",
            "309  The day I've dreaded for years finally came   \n",
            "310                         I betrayed my friend   \n",
            "311                         I betrayed my friend   \n",
            "312                         I betrayed my friend   \n",
            "\n",
            "                                                   URL     Timestamp  \\\n",
            "0    https://www.reddit.com/r/sexualassault/comment...  1.696125e+09   \n",
            "1    https://www.reddit.com/r/sexualassault/comment...  1.696125e+09   \n",
            "2    https://www.reddit.com/r/sexualassault/comment...  1.696137e+09   \n",
            "3    https://www.reddit.com/r/sexualassault/comment...  1.696152e+09   \n",
            "4    https://www.reddit.com/r/sexualassault/comment...  1.696125e+09   \n",
            "..                                                 ...           ...   \n",
            "308  https://www.reddit.com/r/sexualassault/comment...  1.685636e+09   \n",
            "309  https://www.reddit.com/r/sexualassault/comment...  1.685632e+09   \n",
            "310  https://www.reddit.com/r/sexualassault/comment...  1.675359e+09   \n",
            "311  https://www.reddit.com/r/sexualassault/comment...  1.675361e+09   \n",
            "312  https://www.reddit.com/r/sexualassault/comment...  1.675392e+09   \n",
            "\n",
            "                                             Full Text  Upvotes  \\\n",
            "0    I was raped at the age of 13. \\n\\nMyself and m...       14   \n",
            "1                                            [deleted]        4   \n",
            "2    That is horrible. I am sorry you went through ...        2   \n",
            "3    This is awful and I’m sorry, you should have n...        2   \n",
            "4    Sorry for the sudden ending. I haven't talked ...        1   \n",
            "..                                                 ...      ...   \n",
            "308  * Would **legally look into changing yOUR name...        4   \n",
            "309  I'm so sorry this is happening to you. I don't...        3   \n",
            "310  Years ago a friend (we’ll call her Sarah) disc...        5   \n",
            "311  its completely reasonable that you went to a f...        7   \n",
            "312  I would absolutely talk to Jane. odds are the ...        2   \n",
            "\n",
            "                             Flair  \n",
            "0    Warning: SA involving a Minor  \n",
            "1                             None  \n",
            "2                             None  \n",
            "3                             None  \n",
            "4                             None  \n",
            "..                             ...  \n",
            "308                           None  \n",
            "309                           None  \n",
            "310                           Rant  \n",
            "311                           None  \n",
            "312                           None  \n",
            "\n",
            "[313 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel(excel_file_path, index=False)\n",
        "print(f\"DataFrame has been exported to Google Drive: {excel_file_path}\")\n",
        "\n",
        "\n",
        "# Export the DataFrame to an Excel file\n",
        "df.to_excel(excel_file_path, index=False)\n",
        "print(f\"DataFrame has been exported to Google Drive: {excel_file_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fb7FMK9g_J8C",
        "outputId": "79aee613-93f5-4ef8-a433-f16bc07e796a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame has been exported to Google Drive: /content/drive/My Drive/10_11_reddit_data_V4.xlsx\n",
            "DataFrame has been exported to Google Drive: /content/drive/My Drive/10_11_reddit_data_V4.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a DataFrame named df\n",
        "# and you want to examine a specific column 'YourColumnName' and 'Created Date'\n",
        "\n",
        "# Initialize a count variable to keep track of the instances\n",
        "count = 0\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    # Check if the \"Created Date\" is from 2023-08-01 or newer\n",
        "    if row['Created Date'] >= '2022-08-01':\n",
        "        # Check if the current cell contains information and the following row is empty\n",
        "        if pd.notna(row['URL']) and (index + 1 == len(df) or pd.isna(df.at[index + 1, 'URL'])):\n",
        "            count += 1\n",
        "\n",
        "print(f\"Total instances from 2022-08-01 or newer where cell contains info and following row is empty: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMJXkP_TM1rA",
        "outputId": "abc097d4-77e5-4379-852b-4eef61ef0606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total instances from 2022-08-01 or newer where cell contains info and following row is empty: 77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a list of the number of comments for each submission that has comments\n",
        "count = 0\n",
        "empty_row_counts = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    # Check if the \"Created Date\" is from 2022-08-01 or newer\n",
        "    if row['Created Date'] >= '2022-08-01':\n",
        "        if pd.notna(row['URL']):\n",
        "            # Non-empty row\n",
        "            if count > 0:\n",
        "                empty_row_counts.append(count)\n",
        "            count = 0\n",
        "        else:\n",
        "            # Empty row\n",
        "            count += 1\n",
        "\n",
        "# Append the final count if the DataFrame ends with empty rows\n",
        "if count > 0:\n",
        "    empty_row_counts.append(count)\n",
        "\n",
        "print(f\"List of empty row counts between non-empty rows: {empty_row_counts}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG_QyfULQ-BV",
        "outputId": "c059416c-3fa2-4f91-f1ef-e7170d66a4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of empty row counts between non-empty rows: [63, 1, 7, 5, 3, 2, 4, 3, 2, 1, 2, 2, 4, 2, 32, 2, 4, 1, 4, 11, 2, 13, 2, 2, 5, 2, 34, 1, 3, 2, 17, 3, 4, 1, 11, 53, 2, 1, 5, 4, 2, 1, 12, 5, 2, 4, 3, 1, 6, 3, 12, 1, 5, 2, 1, 1, 1, 3, 4, 7, 9, 3, 3, 1, 1, 2, 3, 1, 1, 2, 2, 3, 1, 7, 7, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "\n",
        "# Assuming you have the 'empty_row_counts' list from the previous code\n",
        "\n",
        "# Calculate the mean\n",
        "mean = statistics.mean(empty_row_counts)\n",
        "\n",
        "# Calculate the median\n",
        "median = statistics.median(empty_row_counts)\n",
        "\n",
        "# Calculate the mode\n",
        "try:\n",
        "    mode = statistics.mode(empty_row_counts)\n",
        "except statistics.StatisticsError:\n",
        "    mode = \"No unique mode\"\n",
        "\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Median: {median}\")\n",
        "print(f\"Mode: {mode}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdGZJeFnTaM_",
        "outputId": "eace536f-abee-4846-c694-eb6a72e6f9ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: 5.792207792207792\n",
            "Median: 3\n",
            "Mode: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data fron prior 30 days\n",
        "\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "import asyncpraw\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Allow nested event loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "async def get_reddit_post_info():\n",
        "    # Initialize the Reddit instance\n",
        "    reddit = asyncpraw.Reddit(\n",
        "        username=\"groovydragonfruit\",\n",
        "        password=\"QRrKWuCsc8m$H(R\",\n",
        "        client_id=\"dgrSn-ROpsgbKf1-19zV5A\",\n",
        "        client_secret=\"ds9VdI9GZWvk_2kWUJF4uKorP9s6Vw\",\n",
        "        user_agent=\"SAscrape2 by /u/groovydragonfruit\"\n",
        "    )\n",
        "\n",
        "    subreddit_name = \"sexualassault\"  # Replace with the name of the subreddit you want to search in\n",
        "    keywords = ['police', 'cop', 'cops', 'law enforcement', 'report', 'reporting', 'reported']  # Replace with your desired keywords\n",
        "    desired_flair = 'Reporting/Police'  # Replace with the flair you want to filter by\n",
        "\n",
        "    subreddit = await reddit.subreddit(subreddit_name)  # Define subreddit here\n",
        "\n",
        "    data = []  # List to store scraped data\n",
        "\n",
        "    # Calculate the timestamp for one month ago\n",
        "    one_month_ago = int((datetime.now() - timedelta(days=30)).timestamp())\n",
        "\n",
        "    async for submission in subreddit.search(' '.join(keywords), time_filter='month', limit=None):\n",
        "        # Check if the submission has the desired keywords or the desired flair\n",
        "        if any(keyword in submission.title.lower() or keyword in submission.selftext.lower() for keyword in keywords) or submission.link_flair_text == desired_flair:\n",
        "            # Convert created_utc to a human-readable date (without time)\n",
        "            created_datetime = datetime.utcfromtimestamp(submission.created_utc)\n",
        "            created_date_str = created_datetime.strftime('%Y-%m-%d')\n",
        "\n",
        "            # Check if the submission was posted within the past month\n",
        "            if submission.created_utc >= one_month_ago:\n",
        "                # Extract relevant information from the submission\n",
        "                submission_data = {\n",
        "                    'Title': submission.title,\n",
        "                    'URL': submission.url,\n",
        "                    'Full Text': submission.selftext,\n",
        "                    'Flair': submission.link_flair_text,\n",
        "                    'Created Date': created_date_str\n",
        "                }\n",
        "                data.append(submission_data)\n",
        "\n",
        "            # Load the submission to access its comments\n",
        "            submission = await reddit.submission(id=submission.id)\n",
        "            submission.comments.replace_more(limit=None)\n",
        "            for comment in submission.comments.list():\n",
        "                if isinstance(comment, asyncpraw.models.Comment):\n",
        "                    if any(keyword in comment.body.lower() for keyword in keywords):\n",
        "                        # Convert created_utc to a human-readable date (without time)\n",
        "                        comment_created_datetime = datetime.utcfromtimestamp(comment.created_utc)\n",
        "                        comment_created_date_str = comment_created_datetime.strftime('%Y-%m-%d')\n",
        "\n",
        "                        # Check if the comment was posted within the past month\n",
        "                        if comment.created_utc >= one_month_ago:\n",
        "                            # Extract relevant information from the comment\n",
        "                            comment_data = {\n",
        "                                'Title': submission.title,\n",
        "                                'Comment': comment.body,\n",
        "                                'Created Date': comment_created_date_str\n",
        "                            }\n",
        "                            data.append(comment_data)\n",
        "\n",
        "    # Create a DataFrame from the collected data\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Close the Reddit API client session\n",
        "    await reddit.close()\n",
        "\n",
        "    # Return the DataFrame\n",
        "    return df\n",
        "\n",
        "# Run the asynchronous function using asyncio.run() and store the result in 'df'\n",
        "df = asyncio.run(get_reddit_post_info())\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0Q0Bg3rYvn5",
        "outputId": "e081cc24-4d90-49b2-a4d1-a34021cc507a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-5f160cd8218a>:52: RuntimeWarning: coroutine 'CommentForest.replace_more' was never awaited\n",
            "  submission.comments.replace_more(limit=None)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Title  \\\n",
            "0   Should I report to the police? Scared it’ll ru...   \n",
            "1   Should I report to the police? Scared it’ll ru...   \n",
            "2   Should I report to the police? Scared it’ll ru...   \n",
            "3   Should I report to the police? Scared it’ll ru...   \n",
            "4   Should I report to the police? Scared it’ll ru...   \n",
            "..                                                ...   \n",
            "94               3 Years and police have done nothing   \n",
            "95                      25 F S/A survivor Need advice   \n",
            "96  My attempted rapist (ex) had a daughter this year   \n",
            "97                       I’ve not been the same since   \n",
            "98                                           My story   \n",
            "\n",
            "                                                  URL  \\\n",
            "0   https://www.reddit.com/r/sexualassault/comment...   \n",
            "1                                                 NaN   \n",
            "2                                                 NaN   \n",
            "3                                                 NaN   \n",
            "4                                                 NaN   \n",
            "..                                                ...   \n",
            "94  https://www.reddit.com/r/sexualassault/comment...   \n",
            "95  https://www.reddit.com/r/sexualassault/comment...   \n",
            "96  https://www.reddit.com/r/sexualassault/comment...   \n",
            "97  https://www.reddit.com/r/sexualassault/comment...   \n",
            "98  https://www.reddit.com/r/sexualassault/comment...   \n",
            "\n",
            "                                            Full Text  \\\n",
            "0   I’m starting to realize/accept that I was sexu...   \n",
            "1                                                 NaN   \n",
            "2                                                 NaN   \n",
            "3                                                 NaN   \n",
            "4                                                 NaN   \n",
            "..                                                ...   \n",
            "94  So I was r-ed a little over three years ago. I...   \n",
            "95  \\nThis is going to be a long post and i am sor...   \n",
            "96  TW: discussing the assault and triggers after....   \n",
            "97  I was sexually assaulted by an ex partner afte...   \n",
            "98  Hi, im F(22)\\nWhen I was in highschool I dated...   \n",
            "\n",
            "                                        Flair Created Date  \\\n",
            "0                            Reporting/Police   2023-10-04   \n",
            "1                                         NaN   2023-10-04   \n",
            "2                                         NaN   2023-10-04   \n",
            "3                                         NaN   2023-10-04   \n",
            "4                                         NaN   2023-10-04   \n",
            "..                                        ...          ...   \n",
            "94                                Need Advice   2023-09-20   \n",
            "95  Dating/Relationships After Sexual Assault   2023-09-16   \n",
            "96                                     Coping   2023-10-02   \n",
            "97                                     Coping   2023-09-19   \n",
            "98            Strong Trigger Warning: Graphic   2023-09-30   \n",
            "\n",
            "                                              Comment  \n",
            "0                                                 NaN  \n",
            "1   You should report it. He will keep doing it if...  \n",
            "2   He did this to you. And he did this to himself...  \n",
            "3   Sorry you had this experience. Coercion while ...  \n",
            "4   Please please please dont tell someone who wen...  \n",
            "..                                                ...  \n",
            "94                                                NaN  \n",
            "95                                                NaN  \n",
            "96                                                NaN  \n",
            "97                                                NaN  \n",
            "98                                                NaN  \n",
            "\n",
            "[99 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code that scrapes for keywords in posts and includes all comments and for keywords in comments but not in the post\n",
        "\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "import asyncpraw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Allow nested event loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "async def get_reddit_post_info():\n",
        "    # Initialize the Reddit instance\n",
        "    reddit = asyncpraw.Reddit(\n",
        "        username=\"groovydragonfruit\",\n",
        "        password=\"QRrKWuCsc8m$H(R\",\n",
        "        client_id=\"dgrSn-ROpsgbKf1-19zV5A\",\n",
        "        client_secret=\"ds9VdI9GZWvk_2kWUJF4uKorP9s6Vw\",\n",
        "        user_agent=\"SAscrape2 by /u/groovydragonfruit\"\n",
        "    )\n",
        "\n",
        "async def get_reddit_post_info():\n",
        "    # ... (previous code)\n",
        "\n",
        "    subreddit = await reddit.subreddit(subreddit_name)\n",
        "\n",
        "    data = []  # List to store scraped data\n",
        "\n",
        "    # Calculate the timestamp for August 1, 2022\n",
        "    since_date = int(datetime(2022, 8, 1).timestamp())\n",
        "\n",
        "    # Collect posts with the \"Reporting/Police\" flair\n",
        "    async for submission in subreddit.search(f'flair:\"{desired_flair}\"', time_filter='all', limit=None):\n",
        "        # Convert created_utc to a human-readable date (without time)\n",
        "        created_datetime = datetime.utcfromtimestamp(submission.created_utc)\n",
        "        created_date_str = created_datetime.strftime('%Y-%m-%d')\n",
        "\n",
        "        # Extract relevant information from the submission\n",
        "        submission_data = {\n",
        "            'Title': submission.title,\n",
        "            'URL': submission.url,\n",
        "            'Full Text': submission.selftext,\n",
        "            'Flair': submission.link_flair_text,\n",
        "            'Created Date': created_date_str\n",
        "        }\n",
        "        data.append(submission_data)\n",
        "\n",
        "        # Load the submission to access its comments\n",
        "        submission = await reddit.submission(id=submission.id)\n",
        "        submission.comments.replace_more(limit=None)\n",
        "        for comment in submission.comments.list():\n",
        "            if isinstance(comment, asyncpraw.models.Comment):\n",
        "                # Convert created_utc to a human-readable date (without time)\n",
        "                comment_created_datetime = datetime.utcfromtimestamp(comment.created_utc)\n",
        "                comment_created_date_str = comment_created_datetime.strftime('%Y-%m-%d')\n",
        "\n",
        "                # Extract relevant information from the comment\n",
        "                comment_data = {\n",
        "                    'Title': submission.title,\n",
        "                    'Comment': comment.body,\n",
        "                    'Created Date': comment_created_date_str\n",
        "                }\n",
        "                data.append(comment_data)\n",
        "\n",
        "    # Collect posts containing the specified keywords\n",
        "    async for submission in subreddit.search(' '.join(keywords), time_filter='all', limit=None):\n",
        "        # Convert created_utc to a human-readable date (without time)\n",
        "        created_datetime = datetime.utcfromtimestamp(submission.created_utc)\n",
        "        created_date_str = created_datetime.strftime('%Y-%m-%d')\n",
        "\n",
        "        # Load the submission to access its comments\n",
        "        submission = await reddit.submission(id=submission.id)\n",
        "        submission.comments.replace_more(limit=None)\n",
        "\n",
        "        # Check if the submission was posted on or after August 1, 2022\n",
        "        if submission.created_utc >= since_date:\n",
        "            # Extract relevant information from the submission\n",
        "            submission_data = {\n",
        "                'Title': submission.title,\n",
        "                'URL': submission.url,\n",
        "                'Full Text': submission.selftext,\n",
        "                'Flair': submission.link_flair_text,\n",
        "                'Created Date': created_date_str\n",
        "            }\n",
        "            data.append(submission_data)\n",
        "\n",
        "            for comment in submission.comments.list():\n",
        "                if isinstance(comment, asyncpraw.models.Comment):\n",
        "                    if any(keyword in comment.body.lower() for keyword in keywords):\n",
        "                        # Convert created_utc to a human-readable date (without time)\n",
        "                        comment_created_datetime = datetime.utcfromtimestamp(comment.created_utc)\n",
        "                        comment_created_date_str = comment_created_datetime.strftime('%Y-%m-%d')\n",
        "\n",
        "                        # Extract relevant information from the comment\n",
        "                        comment_data = {\n",
        "                            'Title': submission.title,\n",
        "                            'Comment': comment.body,\n",
        "                            'Created Date': comment_created_date_str\n",
        "                        }\n",
        "                        data.append(comment_data)\n",
        "\n",
        "    # Create a DataFrame from the collected data\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Close the Reddit API client session\n",
        "    await reddit.close()\n",
        "\n",
        "    # Return the DataFrame\n",
        "    return df\n",
        "\n",
        "# Run the asynchronous function using asyncio.run() and store the result in 'df'\n",
        "df = asyncio.run(get_reddit_post_info())\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "gqn2wVU8ZR3d",
        "outputId": "0ab6989d-7e88-4589-91d4-306ef9a1c8e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-347e4193f73f>\u001b[0m in \u001b[0;36m<cell line: 112>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;31m# Run the asynchronous function using asyncio.run() and store the result in 'df'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_reddit_post_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;31m# Print the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     98\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-347e4193f73f>\u001b[0m in \u001b[0;36mget_reddit_post_info\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# ... (previous code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0msubreddit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mreddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubreddit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubreddit_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# List to store scraped data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'reddit' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import nest_asyncio\n",
        "import asyncpraw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Allow nested event loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "async def get_reddit_post_info():\n",
        "    # Initialize the Reddit instance\n",
        "    reddit = asyncpraw.Reddit(\n",
        "        username=\"groovydragonfruit\",\n",
        "        password=\"QRrKWuCsc8m$H(R\",\n",
        "        client_id=\"dgrSn-ROpsgbKf1-19zV5A\",\n",
        "        client_secret=\"ds9VdI9GZWvk_2kWUJF4uKorP9s6Vw\",\n",
        "        user_agent=\"SAscrape2 by /u/groovydragonfruit\"\n",
        "    )\n",
        "\n",
        "    subreddit_name = \"sexualassault\"  # Replace with the name of the subreddit you want to search in\n",
        "    keywords = ['police', 'cop', 'cops', 'law enforcement', 'report', 'reporting', 'reported']  # Replace with your desired keywords\n",
        "    desired_flair = 'Reporting/Police'  # Replace with the flair you want to filter by\n",
        "\n",
        "    subreddit = await reddit.subreddit(subreddit_name)\n",
        "\n",
        "    data = []  # List to store scraped data\n",
        "\n",
        "    # Calculate the timestamp for August 1, 2022\n",
        "    since_date = int(datetime(2022, 8, 1).timestamp())\n",
        "\n",
        "\n",
        "    # Collect posts with the \"Reporting/Police\" flair\n",
        "    async for submission in subreddit.search(f'flair:\"{desired_flair}\"', time_filter='all', limit=None):\n",
        "        # Convert created_utc to a human-readable date (without time)\n",
        "        created_datetime = datetime.utcfromtimestamp(submission.created_utc)\n",
        "        created_date_str = created_datetime.strftime('%Y-%m-%d')\n",
        "\n",
        "        # Extract relevant information from the submission\n",
        "        submission_data = {\n",
        "            'Title': submission.title,\n",
        "            'URL': submission.url,\n",
        "            'Full Text': submission.selftext,\n",
        "            'Flair': submission.link_flair_text,\n",
        "            'Created Date': created_date_str\n",
        "        }\n",
        "        data.append(submission_data)\n",
        "\n",
        "        # Load the submission to access its comments\n",
        "        submission = await reddit.submission(id=submission.id)\n",
        "        submission.comments.replace_more(limit=None)\n",
        "        for comment in submission.comments.list():\n",
        "            if isinstance(comment, asyncpraw.models.Comment):\n",
        "                # Convert created_utc to a human-readable date (without time)\n",
        "                comment_created_datetime = datetime.utcfromtimestamp(comment.created_utc)\n",
        "                comment_created_date_str = comment_created_datetime.strftime('%Y-%m-%d')\n",
        "\n",
        "                # Extract relevant information from the comment\n",
        "                comment_data = {\n",
        "                    'Title': submission.title,\n",
        "                    'Comment': comment.body,\n",
        "                    'Created Date': comment_created_date_str\n",
        "                }\n",
        "                data.append(comment_data)\n",
        "\n",
        "    # Collect posts containing the specified keywords\n",
        "    async for submission in subreddit.search(' '.join(keywords), time_filter='all', limit=None):\n",
        "        # Convert created_utc to a human-readable date (without time)\n",
        "        created_datetime = datetime.utcfromtimestamp(submission.created_utc)\n",
        "        created_date_str = created_datetime.strftime('%Y-%m-%d')\n",
        "\n",
        "        # Load the submission to access its comments\n",
        "        submission = await reddit.submission(id=submission.id)\n",
        "        submission.comments.replace_more(limit=None)\n",
        "\n",
        "        # Check if the submission was posted on or after August 1, 2022\n",
        "        if submission.created_utc >= since_date:\n",
        "            # Extract relevant information from the submission\n",
        "            submission_data = {\n",
        "                'Title': submission.title,\n",
        "                'URL': submission.url,\n",
        "                'Full Text': submission.selftext,\n",
        "                'Flair': submission.link_flair_text,\n",
        "                'Created Date': created_date_str\n",
        "            }\n",
        "            data.append(submission_data)\n",
        "\n",
        "            for comment in submission.comments.list():\n",
        "                if isinstance(comment, asyncpraw.models.Comment):\n",
        "                    if any(keyword in comment.body.lower() for keyword in keywords):\n",
        "                        # Convert created_utc to a human-readable date (without time)\n",
        "                        comment_created_datetime = datetime.utcfromtimestamp(comment.created_utc)\n",
        "                        comment_created_date_str = comment_created_datetime.strftime('%Y-%m-%d')\n",
        "\n",
        "                        # Extract relevant information from the comment\n",
        "                        comment_data = {\n",
        "                            'Title': submission.title,\n",
        "                            'Comment': comment.body,\n",
        "                            'Created Date': comment_created_date_str\n",
        "                        }\n",
        "                        data.append(comment_data)\n",
        "\n",
        "    # Create a DataFrame from the collected data\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Close the Reddit API client session\n",
        "    await reddit.close()\n",
        "\n",
        "    # Return the DataFrame\n",
        "    return df\n",
        "\n",
        "# Run the asynchronous function using asyncio.run() and store the result in 'df'\n",
        "df = asyncio.run(get_reddit_post_info())\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ONj01GgjJRP",
        "outputId": "42c13892-1aa1-4e24-849e-b5708c258650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-464ade954bd4>:50: RuntimeWarning: coroutine 'CommentForest.replace_more' was never awaited\n",
            "  submission.comments.replace_more(limit=None)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
            "<ipython-input-15-464ade954bd4>:73: RuntimeWarning: coroutine 'CommentForest.replace_more' was never awaited\n",
            "  submission.comments.replace_more(limit=None)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  Title  \\\n",
            "0     Should I report to the police? Scared it’ll ru...   \n",
            "1     Should I report to the police? Scared it’ll ru...   \n",
            "2     Should I report to the police? Scared it’ll ru...   \n",
            "3     Should I report to the police? Scared it’ll ru...   \n",
            "4     Should I report to the police? Scared it’ll ru...   \n",
            "...                                                 ...   \n",
            "1258  I was sexually assaulted when I was like 4 and...   \n",
            "1259  I was sexually assaulted when I was like 4 and...   \n",
            "1260  I was sexually assaulted when I was like 4 and...   \n",
            "1261                                  Be Careful in DMs   \n",
            "1262                              Call for Participants   \n",
            "\n",
            "                                                    URL  \\\n",
            "0     https://www.reddit.com/r/sexualassault/comment...   \n",
            "1                                                   NaN   \n",
            "2                                                   NaN   \n",
            "3                                                   NaN   \n",
            "4                                                   NaN   \n",
            "...                                                 ...   \n",
            "1258  https://www.reddit.com/r/sexualassault/comment...   \n",
            "1259                                                NaN   \n",
            "1260                                                NaN   \n",
            "1261  https://www.reddit.com/r/sexualassault/comment...   \n",
            "1262  https://www.reddit.com/r/sexualassault/comment...   \n",
            "\n",
            "                                              Full Text  \\\n",
            "0     I’m starting to realize/accept that I was sexu...   \n",
            "1                                                   NaN   \n",
            "2                                                   NaN   \n",
            "3                                                   NaN   \n",
            "4                                                   NaN   \n",
            "...                                                 ...   \n",
            "1258  I’m 13 rn, so it’s been 9 years. I was sa’d by...   \n",
            "1259                                                NaN   \n",
            "1260                                                NaN   \n",
            "1261  2 days ago I was DMd by a person who saw a pos...   \n",
            "1262  CALL FOR PARTICIPANTS\\n\\nI am currently studyi...   \n",
            "\n",
            "                              Flair Created Date  \\\n",
            "0                  Reporting/Police   2023-10-04   \n",
            "1                               NaN   2023-10-04   \n",
            "2                               NaN   2023-10-04   \n",
            "3                               NaN   2023-10-04   \n",
            "4                               NaN   2023-10-04   \n",
            "...                             ...          ...   \n",
            "1258  Warning: SA involving a Minor   2023-05-05   \n",
            "1259                            NaN   2023-05-05   \n",
            "1260                            NaN   2023-05-06   \n",
            "1261                     Discussion   2023-01-31   \n",
            "1262                 Research/Study   2023-06-07   \n",
            "\n",
            "                                                Comment  \n",
            "0                                                   NaN  \n",
            "1     You should report it. He will keep doing it if...  \n",
            "2     He did this to you. And he did this to himself...  \n",
            "3     Sorry you had this experience. Coercion while ...  \n",
            "4     You don't want to ruin his life, but he has no...  \n",
            "...                                                 ...  \n",
            "1258                                                NaN  \n",
            "1259  1. Not in your family especially not presently...  \n",
            "1260  Your therapist would only be obligated to repo...  \n",
            "1261                                                NaN  \n",
            "1262                                                NaN  \n",
            "\n",
            "[1263 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_drive_path = '/content/drive/My Drive/'\n",
        "excel_file_path = google_drive_path + '10_11_reddit_data_V6.xlsx'\n"
      ],
      "metadata": {
        "id": "RM0gFkl-cPQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel(excel_file_path, index=False)\n",
        "print(f\"DataFrame has been exported to Google Drive: {excel_file_path}\")\n",
        "\n",
        "\n",
        "# Export the DataFrame to an Excel file\n",
        "df.to_excel(excel_file_path, index=False)\n",
        "print(f\"DataFrame has been exported to Google Drive: {excel_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpITuL51cVHG",
        "outputId": "b340c413-267a-4386-c194-3ce5fc4e39b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame has been exported to Google Drive: /content/drive/My Drive/10_11_reddit_data_V6.xlsx\n",
            "DataFrame has been exported to Google Drive: /content/drive/My Drive/10_11_reddit_data_V6.xlsx\n"
          ]
        }
      ]
    }
  ]
}